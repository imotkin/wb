# Задание L0 для Техношколы Wildberries

## Требования

Разработать демонстрационный сервис с простейшим интерфейсом, отображающий данные о заказе.

## Решение

Для работы данного сервиса используются Kafka и PostgreSQL.

Для базовой демонстрации были добавлены три метрики в Prometheus:

- `requests_total` - общее число HTTP-запросов
- `orders_total` - общее число добавленных заказов
- `failed_total` - общее число ошибок при добавлении заказов

При запуске издатель (publisher) для Kafka начинает добавлять новые сообщения в заданный `topic` с заданным интервалом времени. Для настройки этих параметров используется файл конфигурации YAML, в качестве такого примера был добавлен файл [`config.example.yaml`](config.example.yaml) в корне проекта. Для PostgreSQL также используется файл [`example.env`](example.env), в котором хранятся данные для первоначальной инициализации в контейнере.

Подписчик, созданный для работы сервиса заказов, читает сообщения из Kafka, выполняет базовую валидацию наличия необходимых полей в заказе и добавляет полученный заказ в кэш и базу данных. Если произошла ошибка декодирования JSON или заказ не прошёл успешно валидацию, то выполняется его запись в DLQ, настройка `topic` для которой также выполяется в файле конфигурации.

Размера кэша ограничен параметрами из файла конфигурации. При загрузке приложения кэш заполняется заказами из базы данных, если они были ранее туда добавлены. Текущая реализация кэша представляет собой структуру из хэш-таблицы и связного списка для ограничения его размера и быстрого получения необходимого заказа с помощью его уникального ID.

Для получения данных о заказе в веб-браузере используем следующий адрес URL - [`http://localhost:8080/search`](http://localhost:8080/search).

Для получения данных о заказе в JSON-формате отправляем GET-запрос на следующий адрес URL - [`http://localhost:8080/order/$ID`](http://localhost:8080/order/$ID), где `$ID` - номер заказа в формате UUID.

Для получения текущих значений метрик отправляем  GET-запрос на следующий адрес URL - [`http://localhost:8080/metrics`](http://localhost:8080/metrics).

> [!NOTE]
> Возможно, что правильнее было бы для метрик сделать и отдельный контейнер для визуализации с Grafana, однако решил не усложнять этим проект в данном случае.

В качестве линтера используется [`golangci-lint`](https://golangci-lint.run).

Были добавлены базовые unit-тесты для HTTP-хэндлера, сервиса и кэша.

## Запуск

Для запуска проекта используем следующую команду:

```sh
make up
```

С её помощью выполняется создание и запуск всех контейнеров с помощью Docker Compose.

Для остановки всех контейнеров используется команда `make down`.

## Команды

Для работы с проектом доступны команды `make`

Для получения полного списка команд есть `make help`

```sh
Доступные команды:
  make build       - сборка проекта
  make run         - локальный запуск проекта
  make up          - запуск проекта в Docker
  make down        - остановка проекта в Docker
  make test        - запуск тестов
  make cover       - запуск покрытия тестами в HTML
  make lint        - запуск линтера golangci-lint
  make tidy        - запуск проверки зависимостей
  make all         - проверка линтера, запуск тестов и сборка проекта
  make help        - вывод списка доступных команд
```

## Доработка 1

### 1. Использование контекста

```go
func (p *Publisher) Publish(ctx context.Context, key string, value any) (int, error)
```

Статус - `неизвестно`

> [!NOTE]
> В текущем коде используется корневой контекст для всех операций с отменой, за исключением отдельного контекста внутри запуска HTTP-сервера для его тайм-аута отключения. Для издателя в Kafka тоже используется корневой, который передаётся через параметры функции `Publish(...)`. Данный пункт для меня остаётся не очень понятным в плане доработки.

### 2. Метрики добавления и получения для кэша и базы данных

Статус - `доработка`

### 3. Добавить error wrapping

Статус - `выполнено`

### 4. Тесты для базы данных

Статус - `доработка`

### 5. Тесты для логгера

Статус - `доработка`

### 6. Параметры для тайм-аута сервера в файле конфигурации

Статус - `выполнено`

### 7. Интеграционные тесты

Статус - `доработка`

### 8. Трейсинг

Статус - `доработка`
